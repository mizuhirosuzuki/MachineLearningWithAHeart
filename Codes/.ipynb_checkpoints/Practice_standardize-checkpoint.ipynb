{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How does standardization affect accuracies?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this document, I compare prediction accuracies with and without standardizations.\n",
    "As a prediction model, I use a logit regression model for simplicity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, I import libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import itertools\n",
    "import random\n",
    "\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, I load the datasets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load datasets for training my model\n",
    "train_values = pd.read_csv('../Data/train_values.csv', index_col = 'patient_id')\n",
    "train_labels = pd.read_csv('../Data/train_labels.csv', index_col = 'patient_id')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The head of the training features looks like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>slope_of_peak_exercise_st_segment</th>\n",
       "      <th>thal</th>\n",
       "      <th>resting_blood_pressure</th>\n",
       "      <th>chest_pain_type</th>\n",
       "      <th>num_major_vessels</th>\n",
       "      <th>fasting_blood_sugar_gt_120_mg_per_dl</th>\n",
       "      <th>resting_ekg_results</th>\n",
       "      <th>serum_cholesterol_mg_per_dl</th>\n",
       "      <th>oldpeak_eq_st_depression</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>max_heart_rate_achieved</th>\n",
       "      <th>exercise_induced_angina</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>patient_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0z64un</th>\n",
       "      <td>1</td>\n",
       "      <td>normal</td>\n",
       "      <td>128</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>308</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>45</td>\n",
       "      <td>170</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ryoo3j</th>\n",
       "      <td>2</td>\n",
       "      <td>normal</td>\n",
       "      <td>110</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>214</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0</td>\n",
       "      <td>54</td>\n",
       "      <td>158</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>yt1s1x</th>\n",
       "      <td>1</td>\n",
       "      <td>normal</td>\n",
       "      <td>125</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>304</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>77</td>\n",
       "      <td>162</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>l2xjde</th>\n",
       "      <td>1</td>\n",
       "      <td>reversible_defect</td>\n",
       "      <td>152</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>223</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>40</td>\n",
       "      <td>181</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>oyt4ek</th>\n",
       "      <td>3</td>\n",
       "      <td>reversible_defect</td>\n",
       "      <td>178</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>270</td>\n",
       "      <td>4.2</td>\n",
       "      <td>1</td>\n",
       "      <td>59</td>\n",
       "      <td>145</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            slope_of_peak_exercise_st_segment               thal  \\\n",
       "patient_id                                                         \n",
       "0z64un                                      1             normal   \n",
       "ryoo3j                                      2             normal   \n",
       "yt1s1x                                      1             normal   \n",
       "l2xjde                                      1  reversible_defect   \n",
       "oyt4ek                                      3  reversible_defect   \n",
       "\n",
       "            resting_blood_pressure  chest_pain_type  num_major_vessels  \\\n",
       "patient_id                                                               \n",
       "0z64un                         128                2                  0   \n",
       "ryoo3j                         110                3                  0   \n",
       "yt1s1x                         125                4                  3   \n",
       "l2xjde                         152                4                  0   \n",
       "oyt4ek                         178                1                  0   \n",
       "\n",
       "            fasting_blood_sugar_gt_120_mg_per_dl  resting_ekg_results  \\\n",
       "patient_id                                                              \n",
       "0z64un                                         0                    2   \n",
       "ryoo3j                                         0                    0   \n",
       "yt1s1x                                         0                    2   \n",
       "l2xjde                                         0                    0   \n",
       "oyt4ek                                         0                    2   \n",
       "\n",
       "            serum_cholesterol_mg_per_dl  oldpeak_eq_st_depression  sex  age  \\\n",
       "patient_id                                                                    \n",
       "0z64un                              308                       0.0    1   45   \n",
       "ryoo3j                              214                       1.6    0   54   \n",
       "yt1s1x                              304                       0.0    1   77   \n",
       "l2xjde                              223                       0.0    1   40   \n",
       "oyt4ek                              270                       4.2    1   59   \n",
       "\n",
       "            max_heart_rate_achieved  exercise_induced_angina  \n",
       "patient_id                                                    \n",
       "0z64un                          170                        0  \n",
       "ryoo3j                          158                        0  \n",
       "yt1s1x                          162                        1  \n",
       "l2xjde                          181                        0  \n",
       "oyt4ek                          145                        0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_values.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this exercise, I just use the following selected numeric features: `age`, `sex`, `max_heart_rate_achieved`, and `resting_blood_pressure`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_features = ['age',\n",
    "                     'sex',\n",
    "                     'max_heart_rate_achieved',\n",
    "                     'resting_blood_pressure']\n",
    "train_values_subset = train_values[selected_features].astype('float')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_values_subset.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for preprocessing the data\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# the model\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# for combining the preprocess with model training\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# for optimizing parameters of the pipeline\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For predictions, I use `Pipeline`s.\n",
    "Here I define two pipelines, with and without standardizations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_wo_standard = Pipeline(steps = [('logistic', LogisticRegression(solver = 'liblinear'))])\n",
    "pipe_with_standard = Pipeline(steps = [('scale', StandardScaler()),\n",
    "                                       ('logistic', LogisticRegression(solver = 'liblinear'))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For hyperparameter tuning, I use three-fold cross validations.\n",
    "For this, I use the grid between 0.0001 and 10 for the regularization parameter, $C$, and as a regularization term, I attempt L1 and L2.\n",
    "The cost function is hence represented as\n",
    "\\begin{equation*}\n",
    "    J(w) = \\sum_{i=1}^n \\{ - y_i \\log (\\phi (w' x_i)) - (1 - y_i) \\log (1 - \\phi (w' x_i)) \\} + \\frac{1}{C} L(w),\n",
    "\\end{equation*}\n",
    "where $\\phi$ is a logit function: $\\phi(z) = \\frac{1}{1 + e^{-z}}$.\n",
    "The function $L$ is the penalty term, which takes either L1 or L2 norm of $w$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {'logistic__C': np.linspace(0.0001, 10, num = 100),\n",
    "              'logistic__penalty': ['l1', 'l2']}\n",
    "gs_wo_standard = GridSearchCV(estimator = pipe_wo_standard,\n",
    "                              param_grid = param_grid,\n",
    "                              cv = 3)\n",
    "gs_with_standard = GridSearchCV(estimator = pipe_with_standard,\n",
    "                                param_grid = param_grid,\n",
    "                                cv = 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now I estimate the parameters, with and without standardizations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs_wo_standard.fit(train_values_subset, train_labels.heart_disease_present)\n",
    "gs_with_standard.fit(train_values_subset, train_labels.heart_disease_present)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs_wo_standard.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs_with_standard.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To evaluate the performances, I use the log loss as the metric:\n",
    "\\begin{equation*}\n",
    "Log\\ loss = \\sum_{i = 1}^n \\{- y_i \\log(\\phi(w' x_i)) - (1 - y_i) \\log (1 - \\phi(w' x_i))\\}.\n",
    "\\end{equation*}\n",
    "Also, for evaluations, I use the means of scores in five-fold cross validations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(cross_val_score(gs_wo_standard.best_estimator_, train_values_subset, np.ravel(train_labels), cv = 5, scoring = 'neg_log_loss').mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import log_loss\n",
    "\n",
    "cv_score_wo_standard   = cross_val_score(gs_wo_standard.best_estimator_, train_values_subset, train_labels.heart_disease_present, cv = 5, scoring = 'neg_log_loss')\n",
    "cv_score_with_standard = cross_val_score(gs_with_standard.best_estimator_, train_values_subset, train_labels.heart_disease_present, cv = 5, scoring = 'neg_log_loss')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The means of log losses in cross validations are"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Log loss without standardization:', -cv_score_wo_standard.mean(), \n",
    "      ', \\n Log loss with standardization:', -cv_score_with_standard.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Standardization for subset of variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.pipeline import FeatureUnion\n",
    "\n",
    "class ColSelect(BaseEstimator, TransformerMixin):\n",
    "    \n",
    "    # class constructor\n",
    "    def __init__(self, col_list = None):\n",
    "        self.col_list = col_list\n",
    "    def fit(self, X, y = None):\n",
    "        return self\n",
    "    def transform(self, X, y = None):\n",
    "        output = X.loc[:, self.col_list]            \n",
    "        return output\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "std_col_pipe = Pipeline(steps = [('std_col_select', ColSelect()),\n",
    "                                 ('scale', StandardScaler())])\n",
    "no_std_col_pipe = Pipeline(steps = [('non_std_col_select', ColSelect())])\n",
    "\n",
    "input_pipeline = FeatureUnion(transformer_list = [('std_col', std_col_pipe),\n",
    "                                                  ('non_std_col', no_std_col_pipe)])\n",
    "full_pipeline = Pipeline(steps = [('input', input_pipeline),\n",
    "                                  ('logistic', LogisticRegression(solver = 'liblinear'))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "data_columns = list(train_values_subset.columns)\n",
    "\n",
    "std_list_list = []\n",
    "best_mean_cv_list = []\n",
    "for L in range(1, len(data_columns) + 1):\n",
    "    for std_list in itertools.combinations(data_columns, L):\n",
    "        non_std_list = data_columns[:]\n",
    "        for ele in std_list:\n",
    "            non_std_list.remove(ele)\n",
    "        param_grid =  {'input__std_col__std_col_select__col_list': [std_list],\n",
    "                        'input__non_std_col__non_std_col_select__col_list': [non_std_list],\n",
    "                        'logistic__C': np.linspace(0.0001, 10, num = 100),\n",
    "                        'logistic__penalty': ['l1', 'l2']}\n",
    "        gs_cv = GridSearchCV(estimator = full_pipeline,\n",
    "                            param_grid = param_grid,\n",
    "                            cv = 3)\n",
    "        gs_cv.fit(train_values_subset, train_labels.heart_disease_present)\n",
    "#        best_mean_cv = gs_cv.best_score_\n",
    "        random.seed(10)\n",
    "        best_mean_cv = - cross_val_score(gs_cv.best_estimator_, train_values_subset, train_labels.heart_disease_present, cv = 5, scoring = 'neg_log_loss').mean()\n",
    "        std_list_list.append(std_list)\n",
    "        best_mean_cv_list.append(best_mean_cv)\n",
    "        \n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_loss_table = pd.DataFrame(data = {'standardized_col': std_list_list, 'mean_log_loss': best_mean_cv_list})\n",
    "log_loss_table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding a noisy column and standardizing it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_values_with_noise = train_values_subset\n",
    "train_values_with_noise['noise'] = np.random.normal(0, 0.0001, train_values_subset.shape[0])\n",
    "\n",
    "data_columns = list(train_values_with_noise.columns)\n",
    "\n",
    "# with noise standardized\n",
    "std_list = ['noise']\n",
    "non_std_list = data_columns[:]\n",
    "for ele in std_list:\n",
    "    non_std_list.remove(ele)\n",
    "param_grid =  {'input__std_col__std_col_select__col_list': [std_list],\n",
    "                'input__non_std_col__non_std_col_select__col_list': [non_std_list],\n",
    "                'logistic__C': np.linspace(0.0001, 10, num = 100),\n",
    "                'logistic__penalty': ['l1', 'l2']}\n",
    "gs_cv = GridSearchCV(estimator = full_pipeline,\n",
    "                    param_grid = param_grid,\n",
    "                    cv = 3)\n",
    "gs_cv.fit(train_values_with_noise, train_labels.heart_disease_present)\n",
    "random.seed(10)\n",
    "best_mean_cv_noise_std = - cross_val_score(gs_cv.best_estimator_, train_values_with_noise, train_labels.heart_disease_present, cv = 5, scoring = 'neg_log_loss').mean()\n",
    "        \n",
    "# without noise standardized\n",
    "\n",
    "param_grid = {'logistic__C': np.linspace(0.0001, 10, num = 100),\n",
    "              'logistic__penalty': ['l1', 'l2']}\n",
    "\n",
    "gs_wo_noise_std = GridSearchCV(estimator = pipe_wo_standard,\n",
    "                                param_grid = param_grid,\n",
    "                                cv = 3)\n",
    "\n",
    "gs_wo_noise_std.fit(train_values_with_noise, train_labels.heart_disease_present)\n",
    "\n",
    "random.seed(10)\n",
    "best_mean_cv_noise_non_std = - cross_val_score(gs_wo_noise_std.best_estimator_, train_values_with_noise, train_labels.heart_disease_present, cv = 5, scoring = 'neg_log_loss').mean()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Log loss with noise standardized:', best_mean_cv_noise_std,\n",
    "      ', \\n Log loss without noise standardized:', best_mean_cv_noise_non_std)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_score_wo_noise\n",
    "cv_score_with_noise\n",
    "print('Log loss without noise:', -cv_score_wo_noise.mean(), \n",
    "      ', \\n Log loss with noise:', -cv_score_with_noise.mean())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "165px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
